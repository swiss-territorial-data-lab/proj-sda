# 1-Produce tile geometries based on the AoI extent and zoom level
prepare_data.py:  
  srs: EPSG:2056
  datasets:
    shapefile: ./data/labels/MES/tlm-hr-trn-topo.shp
  output_folder: ./output/OD/trne/zoom_16/
  zoom_level: 16 

# 2-Fetch of tiles (online server) and split into 3 datasets: train, test, validation
generate_tilesets.py:
  debug_mode: 
    enable: False  # sample of tiles
    nb_tiles_max: 10
  working_directory: .
  datasets:
    aoi_tiles: output/OD/trne/zoom_16/tiles.geojson
    ground_truth_labels: output/OD/trne/zoom_16/labels.geojson
    image_source:
      type: FOLDER
      location: data/images/SWISSIMAGE/zoom_16/Grayscale_trne/2020/
      srs: 3857
      # type: XYZ       # supported values: 1. MIL = Map Image Layer 2. WMS 3. XYZ
      # location: https://wmts.geo.admin.ch/1.0.0/ch.swisstopo.swissimage-product/default/2020/3857/{z}/{x}/{y}.jpeg
  output_folder: output/OD/trne/zoom_16/
  tile_size: 256      # per side, in pixels
  overwrite: False
  n_jobs: 10
  COCO_metadata:
    year: 2021
    version: 1.0
    description: Swiss Image Hinterground w/ Quarries and Mineral Exploitation Sites detection
    contributor: swisstopo
    url: https://swisstopo.ch
    license:
      name: Unknown
      url:

rgb_to_grayscale.py: 
  working_dir: .
  image_dir: ./data/images/SWISSIMAGE/zoom_16/RGB_trne/2020
  output_dir: ./data/images/SWISSIMAGE/zoom_16/Grayscale_trne/2020

# 3-Train the model with the detectron2 algorithm
train_model.py:
  working_directory: ./output/OD/trne/zoom_16/
  log_subfolder: logs
  sample_tagged_img_subfolder: sample_tagged_images
  COCO_files: # relative paths, w/ respect to the working_folder
    trn: COCO_trn.json
    val: COCO_val.json
    tst: COCO_tst.json
  detectron2_config_file: ../../../../config/detectron2_config.yaml # path relative to the working_folder
  model_weights:
    model_zoo_checkpoint_url: COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml

# 4-Object detection with the optimised trained model
make_detections.py:
  working_directory: ./output/OD/trne/zoom_16/
  log_subfolder: logs
  sample_tagged_img_subfolder: sample_tagged_images
  COCO_files:           # relative paths, w/ respect to the working_folder
    trn: COCO_trn.json
    val: COCO_val.json
    tst: COCO_tst.json
  detectron2_config_file: ../../../../config/detectron2_config.yaml # path relative to the working_folder
  model_weights:
    pth_file: ./logs/model_0002999.pth # trained model minimising the validation loss curve, monitor the training process via tensorboard (tensorboard --logdir </logs>)
  image_metadata_json: img_metadata.json
  rdp_simplification:   # rdp = Ramer-Douglas-Peucker
    enabled: true
    epsilon: 2.0        # cf. https://rdp.readthedocs.io/en/latest/
  score_lower_threshold: 0.05
    
# 5-Evaluate the quality of the detections for the different datasets by calculating metrics
assess_detections.py:
  working_directory: ./output/OD/trne/zoom_16/
  datasets:
    ground_truth_labels: labels.geojson
    image_metadata_json: img_metadata.json
    split_aoi_tiles: split_aoi_tiles.geojson # aoi = Area of Interest
    detections:
      trn: trn_detections_at_0dot05_threshold.gpkg
      val: val_detections_at_0dot05_threshold.gpkg
      tst: tst_detections_at_0dot05_threshold.gpkg
  output_folder: .