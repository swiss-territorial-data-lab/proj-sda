# Produce tile geometries based on the AoI extent and zoom level
prepare_data.py:  
  datasets:
    shapefile: ./data/ground_truth/20240916_GT_all_CH.gpkg       # GT labels
    # fp_shapefile: ./data/FP/20241104_FP.gpkg                     # FP labels
    # empty_tiles_aoi: ./data/AoI/tests/AoI_2020.shp                     # AOI in which additional empty tiles can be selected. Only one 'empty_tiles' option can be selected  
    # empty_tiles_year: 2023                                       # If "empty_tiles_aoi" selected then provide a year. Choice: (1) numeric (i.e. 2020), (2) [year1, year2] (random selection of a year within a given year range) 
    # empty_tiles_shp: ./data/empty_tiles/20240726_EPT.gpkg                  # Provided shapefile of selected empty tiles. Only one 'empty_tiles' option can be selected                     
    category: 'Classe'
  output_folder: ./output/OD/trne/zoom16/run67/
  zoom_level: 16 


# Fetch of tiles (online server) and split into 3 datasets: train, test, validation
generate_tilesets.py:
  debug_mode: 
    enable: False  # sample of tiles
    nb_tiles_max: 2000
  working_directory: .
  datasets:
    aoi_tiles: output/OD/trne/zoom16/run67/tiles.geojson
    ground_truth_labels: output/OD/trne/zoom16/run67/labels.geojson
    # fp_labels:
    #   fp_shp: output/OD/trne/zoom16/run67/FP.geojson
    #   frac_trn: 0.7        # fraction of fp tiles to add to the trn dataset, then the remaining tiles will be split in 2 and added to tst and val datasets
    image_source:
      # ############# 
      # type: FOLDER
      # year: multi-year
      # location: ./output/OD/trne/zoom16/run67/all-images_src
      # srs: "EPSG:3857"
      # ############# 
      # type: WMS                               # supported values: 1. MIL = Map Image Layer 2. WMS 3. XYZ 4. FOLDER
      # location: https://wms.geo.admin.ch/service
      # layers: ch.swisstopo.swissimage
      # srs: "EPSG:2056"
      # ############ 
      type: XYZ                             # supported values: 1. MIL = Map Image Layer 2. WMS 3. XYZ 4. FOLDER
      year: multi-year                   # supported values: 1. multi-year (tiles of different year), 2. <year> (i.e. 2020)
      location: https://wmts.geo.admin.ch/1.0.0/ch.swisstopo.swissimage-product/default/{year}/3857/{z}/{x}/{y}.jpeg
      # ############ 
  # empty_tiles:            # add empty tiles to datasets
  #   tiles_frac: 0.5       # fraction (relative to the number of tiles intersecting labels) of empty tiles to add
  #   frac_trn: 0.7         # fraction of empty tiles to add to the trn dataset, then the remaining tiles will be split in 2 and added to tst and val datasets
  #   keep_oth_tiles: False # keep tiles in oth dataset not intersecting oth labels
  output_folder: output/OD/trne/zoom16/run67/
  tile_size: 256      # per side, in pixels
  overwrite: True
  n_jobs: 10
  seed: 2
  COCO_metadata:
    year: 2024
    version: 1.0
    description: Anthropogenic soils (Ticino, Vaud and swissTML3D 2024)
    contributor: swisstopo
    url: https://swisstopo.ch
    license:
      name: Unknown
      url:


# Train the model with the detectron2 algorithm dir p dir path to geotiff images ath to geotiff images 
train_model.py:
  working_directory: ./output/OD/trne/zoom16/run67/
  log_subfolder: logs
  sample_tagged_img_subfolder: sample_tagged_images
  COCO_files: # relative paths, w/ respect to the working_folder
    trn: COCO_trn.json
    val: COCO_val.json
    tst: COCO_tst.json
  detectron2_config_file: ../../../../../config/detectron2_config.yaml # path relative to the working_folder
  model_weights:
    model_zoo_checkpoint_url: COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml


# Object detection with the optimised trained model
make_detections.py:
  working_directory: ./output/OD/trne/zoom16/run67/
  log_subfolder: logs
  sample_tagged_img_subfolder: sample_tagged_images
  COCO_files:           # relative paths, w/ respect to the working_folder
    trn: COCO_trn.json
    val: COCO_val.json
    tst: COCO_tst.json
  detectron2_config_file: ../../../../../config/detectron2_config.yaml # path relative to the working_folder
  model_weights:
    pth_file: ./logs/model_0005499.pth # trained model minimising the validation loss curve, monitor the training process via tensorboard (tensorboard --logdir </logs>)
  image_metadata_json: img_metadata.json
  rdp_simplification:   # rdp = Ramer-Douglas-Peucker
    enabled: true
    epsilon: 2.0        # cf. https://rdp.readthedocs.io/en/latest/
  score_lower_threshold: 0.05
  remove_det_overlap: True  # if several detections overlap (IoU > 0.5), only the one with the highest confidence score is retained


# Evaluate the detection quality for the different datasets by calculating metrics
assess_detections.py:
  working_directory: ./output/OD/trne/zoom16/run67/
  datasets:
    ground_truth_labels: labels.geojson
    split_aoi_tiles: split_aoi_tiles.geojson # aoi = Area of Interest
    categories: category_ids.json
    detections:
      trn: trn_detections_at_0dot05_threshold.gpkg
      val: val_detections_at_0dot05_threshold.gpkg
      tst: tst_detections_at_0dot05_threshold.gpkg
  output_folder: .
  iou_threshold: 0.1
  area_threshold: 50       # area under which the polygons are discarded from assessment
  metrics_method: macro-average


# Plots (optional)
result_analysis.py:
  working_dir: ./output/OD/trne/zoom16/run67/
  detections: tagged_detections.gpkg


# Assess the final results
merge_detections.py:
  working_dir: ./output/OD/trne/zoom16/run67/
  labels: labels.geojson
  detections:
    trn: trn_detections_at_0dot05_threshold.gpkg
    val: val_detections_at_0dot05_threshold.gpkg
    tst: tst_detections_at_0dot05_threshold.gpkg
  distance: 10 # m, distance use as a buffer to merge close polygons (likely to belong to the same object) together
  iou_threshold: 0.1
  score_threshold: 0.05
  assess: 
    enable: True
    metrics_method: micro-average   # 1: macro-average ; 3: macro-weighted-average ; 2: micro-average


merge_multi_models.py:
  working_dir: output/previous_dets
  output_dir: merged_results
